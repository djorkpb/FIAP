# Decision Match AI ğŸ¤–

## ğŸ“ DescriÃ§Ã£o do Projeto

Este projeto foi desenvolvido como soluÃ§Ã£o para o **Datathon Decision**, um desafio focado em aplicar InteligÃªncia Artificial para otimizar os processos de recrutamento e seleÃ§Ã£o da empresa Decision, uma especialista em bodyshop de TI.

O principal desafio da Decision Ã© encontrar o talento ideal para cada vaga de forma Ã¡gil e precisa. O processo atual, embora robusto, enfrenta dores como a falta de padronizaÃ§Ã£o em entrevistas e a dificuldade em escalar a anÃ¡lise de um grande volume de candidatos, o que pode levar Ã  perda de talentos e a um tempo de contrataÃ§Ã£o elevado.

A soluÃ§Ã£o proposta Ã© o **Decision Match AI**, um MVP (Minimum Viable Product) de um sistema de recomendaÃ§Ã£o inteligente. A ferramenta utiliza um modelo de Machine Learning para analisar o perfil de um candidato em relaÃ§Ã£o a uma vaga e gerar um **"score de compatibilidade"**. O objetivo Ã© ranquear os candidatos, permitindo que o time de recrutadores foque seu tempo e energia nos perfis mais promissores, otimizando todo o fluxo de seleÃ§Ã£o.

O modelo foi treinado com uma base de dados real da Decision, aprendendo a identificar os padrÃµes que diferenciam os candidatos contratados dos demais.

## ğŸ› ï¸ Stack Utilizada

* **Linguagem:** Python 3
* **AnÃ¡lise e Processamento de Dados:** Pandas, NumPy
* **Machine Learning:** Scikit-learn, XGBoost
* **Web App (Dashboard):** Streamlit
* **VisualizaÃ§Ã£o de Dados:** Matplotlib, Seaborn
* **SerializaÃ§Ã£o do Modelo:** Joblib

## ğŸ“‚ Estrutura do RepositÃ³rio

O projeto estÃ¡ organizado da seguinte forma para garantir a manutenibilidade e reprodutibilidade:

â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py                  # Script principal da aplicaÃ§Ã£o com Streamlit
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Onde os dados brutos em JSON devem ser colocados
â”‚   â”‚   â”œâ”€â”€ vagas.json
â”‚   â”‚   â”œâ”€â”€ prospects.json
â”‚   â”‚   â””â”€â”€ Applicants.json (ou a amostra)
â”‚   â””â”€â”€ processed/              # Arquivos intermediÃ¡rios gerados pelo pipeline
â”‚       â”œâ”€â”€ dados_consolidados.json
â”‚       â””â”€â”€ dados_com_features.json
â”œâ”€â”€ images/
â”‚   â””â”€â”€ matriz_confusao.png     # Imagem da matriz de confusÃ£o gerada no treino
â”œâ”€â”€ models/
â”‚   â””â”€â”€ modelo_decision_match_ai.joblib # Modelo treinado e serializado
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_Data_Processing.ipynb     # Notebook da Etapa 1
â”‚   â”œâ”€â”€ 2_Feature_Engineering.ipynb # Notebook da Etapa 2
â”‚   â””â”€â”€ 3_Model_Training.ipynb      # Notebook da Etapa 3
â”œâ”€â”€ README.md                     # DocumentaÃ§Ã£o do projeto
â””â”€â”€ requirements.txt              # Bibliotecas e versÃµes para o ambiente


## âš™ï¸ InstruÃ§Ãµes de InstalaÃ§Ã£o

Para executar este projeto localmente, siga os passos abaixo.

**1. PrÃ©-requisitos:**
* Ter o [Python 3.8+](https://www.python.org/downloads/) instalado.
* Ter o `pip` (gerenciador de pacotes do Python) instalado.

**2. Clone o RepositÃ³rio:**
```bash
git clone [https://github.com/SEU_USUARIO/SEU_REPOSITORIO.git](https://github.com/SEU_USUARIO/SEU_REPOSITORIO.git)
cd SEU_REPOSITORIO
3. Crie um Ambiente Virtual (Recomendado):
Isso isola as dependÃªncias do projeto.

Bash

# Para Windows
python -m venv venv
venv\Scripts\activate

# Para macOS/Linux
python3 -m venv venv
source venv/bin/activate
4. Instale as DependÃªncias:
O arquivo requirements.txt contÃ©m todas as bibliotecas necessÃ¡rias.

Bash

pip install -r requirements.txt
â–¶ï¸ Como Rodar a AplicaÃ§Ã£o
Com o ambiente configurado, vocÃª pode iniciar a aplicaÃ§Ã£o Streamlit.

Certifique-se de que o modelo treinado (modelo_decision_match_ai.joblib) estÃ¡ no diretÃ³rio models/.

Execute o comando abaixo na raiz do projeto:

Bash

streamlit run app/app.py
A aplicaÃ§Ã£o serÃ¡ aberta automaticamente no seu navegador.

ğŸ§  Como Treinar o Modelo Novamente
Para re-executar o pipeline de treinamento e gerar um novo modelo, siga estes passos:

1. Prepare os Dados:

Coloque os arquivos de dados brutos (vagas.json, prospects.json, e Applicants_amostra.json ou o Applicants.json completo) no diretÃ³rio data/raw/.

2. Execute os Notebooks Jupyter:

Ã‰ recomendado usar o Jupyter Notebook ou JupyterLab para executar os scripts de forma interativa.

Execute os notebooks na seguinte ordem, pois eles sÃ£o sequenciais:

notebooks/1_Data_Processing.ipynb: Para ler os dados brutos, consolidÃ¡-los e salvar dados_consolidados.json.

notebooks/2_Feature_Engineering.ipynb: Para carregar os dados consolidados, criar as features de compatibilidade e salvar dados_com_features.json.

notebooks/3_Model_Training.ipynb: Para carregar os dados com features, treinar os modelos, selecionar o melhor e salvar o artefato final (modelo_decision_match_ai.joblib) no diretÃ³rio models/.